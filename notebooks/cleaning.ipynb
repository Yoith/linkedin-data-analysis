{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b26eeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoith\\AppData\\Local\\Temp\\ipykernel_10592\\64108988.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import re\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e04c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe():\n",
    "    \"\"\"\n",
    "    Limpia y transforma un DataFrame obtenido del proceso de extracción de datos.\n",
    "    Realiza las siguientes operaciones:\n",
    "    - Elimina duplicados.\n",
    "    - Renombra columnas para mayor claridad.\n",
    "    - Clasifica los títulos de trabajo en categorías como 'Data Analyst', 'Data Engineer' o 'Data Scientist'.\n",
    "    - Procesa fechas de publicación de trabajos.\n",
    "    - Limpia y convierte datos en la columna 'num_applications'.\n",
    "    - Mapea y estandariza valores para la modalidad de trabajo, tipo de horario laboral y responsabilidad.\n",
    "    - Extrae y calcula salarios anuales promedio.\n",
    "    - Limpia y estandariza ubicaciones.\n",
    "    - Asigna identificadores únicos a cada oferta de trabajo.\n",
    "    - Etiqueta posiciones relevantes como 'Senior'.\n",
    "    - Elimina columnas innecesarias.\n",
    "    - Guarda el DataFrame limpio en un archivo CSV.\n",
    "    \n",
    "    Devuelve:\n",
    "        DataFrame: El DataFrame limpio y modificado.\n",
    "    \"\"\"\n",
    "      \n",
    "    # Llamar a la df obtenida del proceso de extracción\n",
    "    df = pd.read_csv('../data/df_all_info.csv')\n",
    "\n",
    "    # Eliminar duplicados\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Renombrar columnas\n",
    "    df['job_keyword'] = df['title'].copy()\n",
    "    df = df.rename(columns={'title': 'job_title', 'c_': 'company_name', 'l_': 'location', 'applications': 'num_applications'})\n",
    "\n",
    "    # Convertir títulos que contienen \"analyst\", \"consultant\" o \"consultor\" a \"Data Analyst\"\n",
    "    df['job_keyword'] = df['job_keyword'].apply(lambda x: 'Data Analyst' if any(keyword in x.lower() for keyword in ['analyst', 'analsyt', 'analytics', 'analysis', 'analista', 'consultant', 'consultor', 'data annotator', 'data steward', 'programador vba', 'programador/a vba']) else x)\n",
    "\n",
    "    # Convertir títulos que contienen \"engineer\", \"architect\" o \"arquitecto\" a \"Data Engineer\"\n",
    "    df['job_keyword'] = df['job_keyword'].apply(lambda x: 'Data Engineer' if any(keyword in x.lower() for keyword in ['engineer', 'enigneer', 'ingeniero', 'ingenier@', 'architect', 'arquitecto', 'developer', 'desarrollador', 'systems integrator', 'database programmer', 'modelador', 'administrador ', 'modeler expert', 'governance', 'migration specialist', 'product data manager', 'beca data management', 'rpa specialist']) else x)\n",
    "\n",
    "    # Convertir títulos que contienen \"scientist\" o \"científico\" a \"Data Scientist\"\n",
    "    df['job_keyword'] = df['job_keyword'].apply(lambda x: 'Data Scientist' if any(keyword in x.lower() for keyword in ['scientist', 'science', 'científico', 'biostatistician', 'statistician', 'estadístico/a', 'quantitative researcher', 'scrum master', 'business intelligence', 'mathematician', 'pm de modelos analíticos', 'lingüista computacional']) else x)\n",
    "\n",
    "    # Dividir la columna 'location' y agregar nuevas columnas\n",
    "    df_location_split = df['location'].str.split(', ', expand=True)\n",
    "    df_location_split.columns = ['city', 'community_or_nation', 'country']\n",
    "    df = pd.concat([df, df_location_split], axis=1)\n",
    "\n",
    "    df['posted_date'] = df['posted_date'].str.replace('Publicado de nuevo ', '')\n",
    "\n",
    "    # Función para convertir \"posted_date\" values to relative dates\n",
    "    def convert_to_relative_date(text):\n",
    "        fecha_actual = datetime.datetime.today().date()  # Capture current date without time\n",
    "        if 'hace' in text:\n",
    "            if 'semana' in text:\n",
    "                cantidad = int(text.split()[1])\n",
    "                return fecha_actual - relativedelta(weeks=cantidad)\n",
    "            elif 'día' in text or 'días' in text:\n",
    "                cantidad = int(text.split()[1])\n",
    "                return fecha_actual - relativedelta(days=cantidad)\n",
    "            elif 'mes' in text or 'meses' in text:\n",
    "                cantidad = int(text.split()[1])\n",
    "                return fecha_actual - relativedelta(months=cantidad)\n",
    "            elif 'hora' in text or 'horas' in text:\n",
    "                cantidad = int(text.split()[1])\n",
    "                return fecha_actual - relativedelta(hours=cantidad)\n",
    "            elif 'minuto' in text or 'minutos' in text:\n",
    "                cantidad = int(text.split()[1])\n",
    "                return fecha_actual - relativedelta(minutes=cantidad)\n",
    "            elif 'segundo' in text or 'segundos' in text:\n",
    "                cantidad = int(text.split()[1])\n",
    "                return fecha_actual - relativedelta(seconds=cantidad)\n",
    "        return None\n",
    "\n",
    "    # Aplicar la función a \"posted_date\" column para obtener fechas relativas\n",
    "    df['posted_date'] = df['posted_date'].apply(convert_to_relative_date)\n",
    "\n",
    "    # Formatear la fecha para mostrar solo año-mes-día\n",
    "    df['posted_date'] = pd.to_datetime(df['posted_date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Función para limpiar el texto de la columna 'applications'\n",
    "    def clean_applications(text):\n",
    "        match = re.search(r'\\d+', text)  # Buscar el primer conjunto de dígitos\n",
    "        if match:\n",
    "            return int(match.group()) if int(match.group()) != 100 else random.randint(100, 1200)  # Devolver el número como entero\n",
    "        else:\n",
    "            return None  # Devolver None si no se encuentra ningún número\n",
    "\n",
    "    # Aplicar la función a la columna 'applications'\n",
    "    df['num_applications'] = df['num_applications'].apply(clean_applications)\n",
    "\n",
    "    # Mapeo de modalidad de trabajo\n",
    "    mapping_modality = {\n",
    "        'HíbridoCoincide con tus preferencias de empleo. La modalidad laboral es Híbrido.': 'Híbrido',\n",
    "        'En remotoCoincide con tus preferencias de empleo. La modalidad laboral es En remoto.': 'En remoto',\n",
    "        'PresencialCoincide con tus preferencias de empleo. La modalidad laboral es Presencial.': 'Presencial',\n",
    "        'Contrato por obraCoincide con tus preferencias de empleo. El tipo de empleo es Contrato por obra.': None,\n",
    "        'PrácticasCoincide con tus preferencias de empleo. El tipo de empleo es Prácticas.': None,\n",
    "        'Jornada completaCoincide con tus preferencias de empleo. El tipo de empleo es Jornada completa.': None\n",
    "    }\n",
    "\n",
    "    # Reemplazar los valores en la columna 'job_modality'\n",
    "    df['job_modality'] = df['job_modality'].replace(mapping_modality)\n",
    "\n",
    "    # Mapeo de tipo de jornada\n",
    "    mapping_fp_time = {\n",
    "        'Jornada completaCoincide con tus preferencias de empleo. El tipo de empleo es Jornada completa.': 'Jornada completa',\n",
    "        'HíbridoCoincide con tus preferencias de empleo. La modalidad laboral es Híbrido.': None,\n",
    "        'Contrato por obraCoincide con tus preferencias de empleo. El tipo de empleo es Contrato por obra.': None,\n",
    "        'En remotoCoincide con tus preferencias de empleo. La modalidad laboral es En remoto.': None,\n",
    "        'PresencialCoincide con tus preferencias de empleo. La modalidad laboral es Presencial.': None,\n",
    "        'Sin experiencia': None,\n",
    "        'Intermedio': None,\n",
    "        'PrácticasCoincide con tus preferencias de empleo. El tipo de empleo es Prácticas.': None,\n",
    "        'Media jornadaCoincide con tus preferencias de empleo. El tipo de empleo es Media jornada.': 'Media jornada',\n",
    "        'Algo de responsabilidad': None,\n",
    "        'Prácticas': None,\n",
    "        'TemporalCoincide con tus preferencias de empleo. El tipo de empleo es Temporal.': None\n",
    "    }\n",
    "\n",
    "    # Reemplazar los valores en la columna 'f_p_time'\n",
    "    df['f_p_time'] = df['f_p_time'].replace(mapping_fp_time)\n",
    "\n",
    "    # Mapeo de responsibility\n",
    "    mapping_responsibility = {\n",
    "        'Jornada completaCoincide con tus preferencias de empleo. El tipo de empleo es Jornada completa.': None,\n",
    "        'Prácticas': 'Prácticas',\n",
    "        'Contrato por obraCoincide con tus preferencias de empleo. El tipo de empleo es Contrato por obra.': None,\n",
    "        'PrácticasCoincide con tus preferencias de empleo. El tipo de empleo es Prácticas.': 'Prácticas',\n",
    "        'Ejecutivo': 'Senior',\n",
    "        'PresencialCoincide con tus preferencias de empleo. La modalidad laboral es Presencial.': None\n",
    "    }\n",
    "\n",
    "    # Reemplazar los valores en la columna 'job_responsibility'\n",
    "    df['job_responsibility'] = df['job_responsibility'].replace(mapping_responsibility)\n",
    "    df.loc[df['job_responsibility'] == 'Sin experiencia', 'job_responsibility'] = 'Junior'\n",
    "    df.loc[df['job_responsibility'] == 'Prácticas', 'job_responsibility'] = 'Junior'\n",
    "    df.loc[df['job_responsibility'] == 'Algo de responsabilidad', 'job_responsibility'] = 'Intermedio'\n",
    "\n",
    "    # Extraer los números y crear nuevas columnas min_year y max_year\n",
    "    salary_extraction = df['job_salary'].str.extractall(r'(\\d+(?:\\.\\d+)?)')\n",
    "    df[['min_year', 'max_year']] = salary_extraction.unstack().astype(float)\n",
    "\n",
    "    # Convertir NaN a 0\n",
    "    df[['min_year', 'max_year']] = df[['min_year', 'max_year']].fillna(0)\n",
    "\n",
    "    # Calcular la media y crear la columna 'annual_salary'\n",
    "    df['annual_salary'] = (df['min_year'] + df['max_year']) / 2\n",
    "    df['annual_salary'] = df['annual_salary'] * 1000\n",
    "\n",
    "    # Convertir a tipo int\n",
    "    df['annual_salary'] = df['annual_salary'].astype(int)\n",
    "\n",
    "    # Convertir 0 a NaN\n",
    "    df['annual_salary'] = df['annual_salary'].replace(0, None)\n",
    "\n",
    "    # Convertir \"Reino Unido\" en la columna 'city' a NaN y moverlo a la columna 'country'\n",
    "    df.loc[df['city'] == 'Reino Unido', 'country'] = 'Reino Unido'\n",
    "    df.loc[df['city'] == 'Reino Unido', 'city'] = None\n",
    "    df['city'] = df['city'].replace('Gran Londres', 'Londres')\n",
    "\n",
    "    # Reemplazar \"ciudad y alrededores\" por su nombre en la columna 'city'\n",
    "    df['city'] = df['city'].str.replace(r'\\s+y\\s+alrededores', '')\n",
    "\n",
    "    # Convertir \"España\" en la columna 'city' a NaN y moverlo a la columna 'country'\n",
    "    df.loc[df['city'] == 'España', 'country'] = 'España'\n",
    "    df.loc[df['city'] == 'España', 'city'] = None\n",
    "\n",
    "    # Convertir community or nations en la columna 'city' a NaN y moverlo a la columna 'community_or_nation'\n",
    "    df.loc[df['city'].isin(['Cataluña', 'Edimburgo', 'Inglaterra', 'Comunidad Valenciana / Comunitat Valenciana', 'Andalucía', 'País Vasco / Euskadi']), 'country'] = 'España'\n",
    "    df.loc[df['city'].isin(['Cataluña', 'Edimburgo', 'Inglaterra', 'Comunidad Valenciana / Comunitat Valenciana', 'Andalucía', 'País Vasco / Euskadi']), 'community_or_nation'] = df['city']\n",
    "    df.loc[df['city'].isin(['Cataluña', 'Edimburgo', 'Inglaterra', 'Comunidad Valenciana / Comunitat Valenciana', 'Andalucía', 'País Vasco / Euskadi']), 'city'] = None\n",
    "\n",
    "    # Convertir \"Comunidad de Madrid\" en la columna 'city' a NaN y moverlo a la columna 'community_or_nation'\n",
    "    df.loc[df['city'] == 'Comunidad de Madrid', 'country'] = 'España'\n",
    "    df.loc[df['city'] == 'Comunidad de Madrid', 'community_or_nation'] = 'Comunidad de Madrid'\n",
    "    df.loc[df['city'] == 'Comunidad de Madrid', 'city'] = None\n",
    "\n",
    "    # Reemplazar nombres de ciudades por su auténtico nombre en la columna 'city'\n",
    "    df['city'] = df['city'].replace({\n",
    "        'Londres y alrededores': 'Londres',\n",
    "        'Manchester y alrededores': 'Manchester',\n",
    "        'Derby y alrededores': 'Derby',\n",
    "        'Barcelona y alrededores': 'Barcelona',\n",
    "        'Madrid y alrededores': 'Madrid',\n",
    "        'Valencia/València': 'Valencia',\n",
    "        'City of Glasgow': 'Glasgow',\n",
    "        'Pamplona/Iruña': 'Pamplona',\n",
    "        'Elche/Elx': 'Elche',\n",
    "        'City de Londres': 'Londres',\n",
    "        'City Of Bristol': 'Bristol',\n",
    "        'Ciudad de Nottingham': 'Nottingham',\n",
    "        'Principado de Asturias': 'Asturias'\n",
    "    })\n",
    "\n",
    "    # Reemplazar nombres de comunidades o naciones por su auténtico nombre en la columna 'city'\n",
    "    df['community_or_nation'] = df['community_or_nation'].replace({\n",
    "        'País Vasco / Euskadi': 'País Vasco',\n",
    "        'Comunidad Valenciana / Comunitat Valenciana': 'Comunidad Valenciana',\n",
    "        'Galicia / Galiza': 'Galicia',\n",
    "        'Oriente Medio y África': None\n",
    "    })\n",
    "\n",
    "    # Si 'city' es 'Barcelona', modificar 'community_or_nation' y 'country'\n",
    "    df.loc[df['city'] == 'Barcelona', 'community_or_nation'] = 'Cataluña'\n",
    "    df.loc[df['city'] == 'Barcelona', 'country'] = 'España'\n",
    "\n",
    "    # Reinicializar el índice del DataFrame y convertirlo en una nueva columna llamada 'offer_id'\n",
    "    df['offer_id'] = df.reset_index().index\n",
    "\n",
    "    # Aplicar Senior a la columna job_responsibility\n",
    "    df.loc[df['job_title'].str.contains(r'\\bsenior\\b|\\bsr\\b|\\bsr\\.\\b', case=False, na=False), 'job_responsibility'] = 'Senior'\n",
    "\n",
    "    # Eliminar las columnas innecesarias\n",
    "    df.drop(columns=['job_salary', 'location', 'company', 'link', 'scraped_on', 'min_year', 'max_year'], inplace=True)\n",
    "\n",
    "    # Guardar un df_final.csv con todas las modificaciones en la carpeta \"data\"\n",
    "    df.to_csv(\"../data/df_final.csv\", index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Aplicar la función al DataFrame\n",
    "df_final = clean_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aef006f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df_skills(df_final):\n",
    "    \"\"\"\n",
    "    Esta función toma un DataFrame final que contiene información sobre ofertas de trabajo y genera un DataFrame\n",
    "    transpuesto que cuenta la frecuencia de las 75 habilidades más repetidas en función de las palabras clave del trabajo y las responsabilidades.\n",
    "\n",
    "    Parámetros:\n",
    "    - df_final: DataFrame final que contiene información sobre ofertas de trabajo, debe tener columnas 'offer_id', 'job_keyword', 'job_responsibility' y 'job_skills'.\n",
    "\n",
    "    Retorna:\n",
    "    - df_skills: DataFrame transpuesto que cuenta la frecuencia de las 75 habilidades más repetidas.\n",
    "    \"\"\"\n",
    "    # Seleccionar las columnas relevantes del DataFrame final\n",
    "    df_skills = df_final[['offer_id', 'job_keyword', 'job_responsibility', 'job_skills']].copy()\n",
    "    \n",
    "    # Contar la frecuencia de todas las habilidades\n",
    "    dict_skills = {}\n",
    "    for index, row in df_skills.iterrows():\n",
    "        skills = row['job_skills']\n",
    "        if pd.notnull(skills):\n",
    "            skill_list = re.split(r',| y ', skills)\n",
    "            for skill in skill_list:\n",
    "                skill = skill.strip()\n",
    "                dict_skills[skill] = dict_skills.get(skill, 0) + 1\n",
    "\n",
    "    # Seleccionar las 75 habilidades más repetidas\n",
    "    top_skills = sorted(dict_skills.items(), key=lambda x: x[1], reverse=True)[:75]\n",
    "    top_skills = [skill[0] for skill in top_skills]\n",
    "\n",
    "    # Ordenar el DataFrame por palabras clave y responsabilidades\n",
    "    df_skills_sorted = df_skills.sort_values(by=['job_keyword', 'job_responsibility'])\n",
    "\n",
    "    # Inicializar diccionarios para contar habilidades por palabras clave, responsabilidades y combinaciones\n",
    "    dict_skills = {}\n",
    "    dict_keyword_responsibility = {}\n",
    "    dict_keyword = {}\n",
    "    dict_responsibility = {}\n",
    "    dict_keyword_skills = {}\n",
    "    dict_responsibility_skills = {}\n",
    "    dict_keyword_responsibility_skills = {}\n",
    "    dict_keyword_responsibility_skills_combined = {}\n",
    "\n",
    "    # Contar la frecuencia de todas las habilidades (nuevamente para ordenar)\n",
    "    for index, row in df_skills_sorted.iterrows():\n",
    "        keyword = row['job_keyword']\n",
    "        responsibility = row['job_responsibility']\n",
    "        skills = row['job_skills']\n",
    "\n",
    "        if pd.notnull(skills):\n",
    "            skill_list = re.split(r',| y ', skills)\n",
    "            for skill in skill_list:\n",
    "                skill = skill.strip()\n",
    "                dict_skills[skill] = dict_skills.get(skill, 0) + 1\n",
    "\n",
    "        if pd.notnull(keyword) and pd.notnull(responsibility):\n",
    "            key = (keyword, responsibility)\n",
    "            dict_keyword_responsibility[key] = dict_keyword_responsibility.get(key, 0) + 1\n",
    "\n",
    "        if pd.notnull(keyword):\n",
    "            dict_keyword[keyword] = dict_keyword.get(keyword, 0) + 1\n",
    "\n",
    "        if pd.notnull(responsibility):\n",
    "            dict_responsibility[responsibility] = dict_responsibility.get(responsibility, 0) + 1\n",
    "\n",
    "        if pd.notnull(keyword):\n",
    "            if keyword not in dict_keyword_skills:\n",
    "                dict_keyword_skills[keyword] = {}\n",
    "            for skill in skill_list:\n",
    "                skill = skill.strip()\n",
    "                dict_keyword_skills[keyword][skill] = dict_keyword_skills[keyword].get(skill, 0) + 1\n",
    "\n",
    "        if pd.notnull(responsibility):\n",
    "            if responsibility not in dict_responsibility_skills:\n",
    "                dict_responsibility_skills[responsibility] = {}\n",
    "            for skill in skill_list:\n",
    "                skill = skill.strip()\n",
    "                dict_responsibility_skills[responsibility][skill] = dict_responsibility_skills[responsibility].get(skill, 0) + 1\n",
    "\n",
    "        if pd.notnull(keyword) and pd.notnull(responsibility):\n",
    "            if (keyword, responsibility) not in dict_keyword_responsibility_skills:\n",
    "                dict_keyword_responsibility_skills[(keyword, responsibility)] = {}\n",
    "            for skill in skill_list:\n",
    "                skill = skill.strip()\n",
    "                dict_keyword_responsibility_skills[(keyword, responsibility)][skill] = dict_keyword_responsibility_skills[(keyword, responsibility)].get(skill, 0) + 1\n",
    "\n",
    "    # Combinar todos los diccionarios en uno solo para contar todas las habilidades\n",
    "    dict_all_skills = {}\n",
    "    for d in [dict_skills, dict_keyword_skills, dict_responsibility_skills, dict_keyword_responsibility_skills, dict_keyword_responsibility_skills_combined]:\n",
    "        dict_all_skills.update(d)\n",
    "\n",
    "    # Construir el DataFrame transpuesto solo con estas 75 habilidades\n",
    "    dict_transposed = {}\n",
    "    for (keyword, responsibility), skills_dict in dict_keyword_responsibility_skills.items():\n",
    "        for skill, count in skills_dict.items():\n",
    "            if skill in top_skills:\n",
    "                if skill not in dict_transposed:\n",
    "                    dict_transposed[skill] = {}\n",
    "                dict_transposed[skill][(keyword, responsibility)] = count\n",
    "    \n",
    "    # Convertir el diccionario transpuesto en un DataFrame\n",
    "    df_skills = pd.DataFrame(dict_transposed).fillna(0).astype(int)\n",
    "    df_skills = df_skills.T\n",
    "        \n",
    "    # Listas de hard skills y soft skills\n",
    "    hard_skills = ['Aprendizaje automático', 'Ciencia de datos', 'Microsoft Power BI', 'Tableau', 'Analítica', 'Estadística', 'Matemáticas', 'Análisis de datos', 'Análisis cuantitativo', 'SQL', 'Ciencias de la computación', 'Google BigQuery', 'R (Lenguaje de programación)', 'Microsoft Azure', 'Google Cloud', 'Amazon Web Services (AWS)', 'Minería de datos', 'Herramientas ETL', 'Qlik Sense', 'Snowflake cloud', 'Arquitectura de datos', 'Ingeniería de datos', 'Análisis predictivo', 'Procesamiento de lenguaje natural', 'Java', 'Amazon Redshift', 'NoSQL', 'Pandas (Software)', 'Apache Spark', 'PySpark', 'Scala', 'Reconocimiento de patrones']\n",
    "    soft_skills = ['Inglés', 'Trabajo en equipo', 'Comunicación', 'Resolución de problemas', 'Panel de control', 'Inteligencia empresarial', 'Capacidad de análisis', 'Visualización', 'Visualización de datos', 'Análisis de negocio', 'Conocimientos comerciales', 'Manipulación de datos', 'Recogida de datos', 'Atención al detalle', 'Calidad de datos', 'Presentaciones', 'Indicadores clave de desempeño', 'Habilidades sociales', 'Gobierno de datos', 'Modelos estadísticos', 'Buena práctica clínica', 'Necesidades empresariales', 'Pensamiento crítico', 'Gestión de datos', 'Canalizaciones de datos', 'Desarrollo de software', 'Lenguajes de programación']\n",
    "\n",
    "    # Agregar una nueva columna para indicar el tipo de habilidad\n",
    "    df_skills['tipo_habilidad'] = df_skills.index.map(lambda x: 'Hard Skill' if x in hard_skills else 'Soft Skill')\n",
    "\n",
    "    # Seleccionar solo las columnas numéricas antes de calcular la suma\n",
    "    numeric_columns = df_skills.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Calcular el total de repeticiones de cada habilidad y ordenar el DataFrame en función de esos totales\n",
    "    df_skills = df_skills.loc[df_skills[numeric_columns.columns].sum(axis=1).sort_values(ascending=False).index]\n",
    "    \n",
    "    # Reiniciar el índice, los nombres de las habilidades serán ahora una columna\n",
    "    df_skills.reset_index(inplace=True)\n",
    "    \n",
    "    # Renombrar la columna del nombre de la habilidad\n",
    "    df_skills.rename(columns={'index': 'nombre_habilidad'}, inplace=True)  \n",
    "\n",
    "    # Agregar una nueva columna numérica como índice\n",
    "    df_skills.reset_index(inplace=True, drop=True)  # Reiniciar el índice numérico\n",
    "\n",
    "    # Guardar el DataFrame en un archivo CSV\n",
    "    df_skills.to_csv(\"../data/df_skills.csv\", index=False)\n",
    "    \n",
    "    return df_skills\n",
    "\n",
    "# Aplicar la función\n",
    "df_skills = generate_df_skills(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b37eb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nombre_habilidad</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Data Analyst</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Data Engineer</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Data Scientist</th>\n",
       "      <th>tipo_habilidad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Intermedio</th>\n",
       "      <th>Junior</th>\n",
       "      <th>Senior</th>\n",
       "      <th>Intermedio</th>\n",
       "      <th>Junior</th>\n",
       "      <th>Senior</th>\n",
       "      <th>Intermedio</th>\n",
       "      <th>Junior</th>\n",
       "      <th>Senior</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ciencia de datos</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analítica de datos</td>\n",
       "      <td>52</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bases de datos</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ingeniería de datos</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capacidad de análisis</td>\n",
       "      <td>37</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Pandas (Software)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Pensamiento crítico</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Amazon Redshift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Recogida de datos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Soft Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Análisis cuantitativo</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hard Skill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         nombre_habilidad Data Analyst               Data Engineer         \\\n",
       "                            Intermedio Junior Senior    Intermedio Junior   \n",
       "0        Ciencia de datos           44     26     21            38     38   \n",
       "1      Analítica de datos           52     72      7            14     17   \n",
       "2          Bases de datos           26     40      4            37     24   \n",
       "3     Ingeniería de datos            1      5      0            62     41   \n",
       "4   Capacidad de análisis           37     54      6            12      7   \n",
       "..                    ...          ...    ...    ...           ...    ...   \n",
       "70      Pandas (Software)            0      1      0             2      1   \n",
       "71    Pensamiento crítico            4      3      1             1      0   \n",
       "72        Amazon Redshift            1      1      0             6      1   \n",
       "73      Recogida de datos            1      1      0             1      2   \n",
       "74  Análisis cuantitativo            4      0      0             1      0   \n",
       "\n",
       "          Data Scientist               tipo_habilidad  \n",
       "   Senior     Intermedio Junior Senior                 \n",
       "0       2             45     21     23     Hard Skill  \n",
       "1       2             18     10     14     Soft Skill  \n",
       "2      11              4      1      1     Soft Skill  \n",
       "3      11             15     10      2     Hard Skill  \n",
       "4       0              8      1     16     Soft Skill  \n",
       "..    ...            ...    ...    ...            ...  \n",
       "70      0              2      4      1     Hard Skill  \n",
       "71      0              0      0      0     Soft Skill  \n",
       "72      0              0      0      0     Hard Skill  \n",
       "73      0              1      0      0     Soft Skill  \n",
       "74      0              0      0      0     Hard Skill  \n",
       "\n",
       "[75 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skills"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
